{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer Model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO59ahS+u2HHHn2F8ouqhqI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reban87/HuggingFace/blob/main/01.%20Transformer%20Model%20/%20Transformer_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cKSYZq-pP4G8"
      },
      "outputs": [],
      "source": [
        "#@ INITIALIZATION TO AVOID RELOADING THE SAME PROJECT AND TO VISUALIZE\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@ UNCOMMENT FOR INSTALLATION\n",
        "#!pip install transformers"
      ],
      "metadata": {
        "id": "p3N_nLozQuiV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most basic object in the ðŸ¤— Transformers library is the pipeline() function. It connects a model with its necessary preprocessing and postprocessing steps, allowing us to directly input any text and get an intelligible answe"
      ],
      "metadata": {
        "id": "lNse1G1FRaTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "XuZQZ5W4RLbJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SENTIMENT ANALYSIS : SINGLE SENTENCE\n",
        "# By default, this pipeline selects a particular pretrained model that has been fine-tuned for sentiment analysis in English.\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier(\"I am very happy to start journey with HuggingFace\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gl2sN4lRwdW",
        "outputId": "5f55b57b-0c41-48e5-8482-31f0a55bd349"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9998515844345093}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SENTIMENT ANALYSIS : MULTIPLE SENTENCES\n",
        "classifier([\"I love studying NLP\",\n",
        "            \"I hate copying codes without understanding\",\n",
        "            \"Study from documentation is a best practise\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfZBMfb0SKNU",
        "outputId": "8bea899b-a8d2-4d4e-a442-7725c1f6b9ff"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.999051034450531},\n",
              " {'label': 'NEGATIVE', 'score': 0.9991101622581482},\n",
              " {'label': 'POSITIVE', 'score': 0.9969923496246338}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Pipelines`\n",
        "\n",
        "There are three main steps involved when we pass some text to a `pipeline`:\n",
        "\n",
        "1. The text is preprocessed into a format the model can understand.\n",
        "2. The preprocessed inputs are passed to the model.\n",
        "3. The predictions of the model are post-processed, so you can make sense of    them."
      ],
      "metadata": {
        "id": "FvihwwQ4TVwt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Zero-shot classification`\n",
        "\n",
        "- It allows us to specify which labels to use for the classification, so that one don't have to rely on the labels of the pretrained model. \n",
        "- Similar like above examples, model has classified into positive and negative labels, it can also be classified using any set of labels we like.\n",
        "- This pipeline is called zero-shot because no need to fine-tune the model on the data to use it. It can directly return probability scores for any list of labels we want!"
      ],
      "metadata": {
        "id": "Ot7PgHShT4NP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "classifier(\"HuggingFace is a informative course library for data scientist \",\n",
        "           candidate_labels = [\"education\", \"politics\", \"business\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjDWTGlKS0Ut",
        "outputId": "6be05367-e6ae-4816-b74d-87887d1a1532"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': ['education', 'business', 'politics'],\n",
              " 'scores': [0.8056657910346985, 0.13851258158683777, 0.05582159385085106],\n",
              " 'sequence': 'HuggingFace is a informative course library for data scientist '}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Text Generation`\n",
        "- gives a prompt and the pipeline will auto complete it by generating the remaining text.\n",
        "- generates random text, thus the output could be inconsistant"
      ],
      "metadata": {
        "id": "QCW3CVhcf7R5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text-generation\")\n",
        "generator(\"This is the very begining of text generation pipeline where\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B16rLanHU_sU",
        "outputId": "bdb7d875-48a5-422f-d521-84a938e527d9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to gpt2 (https://huggingface.co/gpt2)\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'This is the very begining of text generation pipeline where people can express ideas without fear or coercion, and they have the ability to produce the desired things in a very real instant, and they have no control over where it goes, how it is interpreted'}]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The output of the text generator can be controlled using\n",
        "# num_return_sequences and max_length as follows\n",
        "generator(\"This is the begining of hugging face where\", num_return_sequences = 2, max_length = 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O99UQYcgkZI",
        "outputId": "52902567-df76-401a-cf27-3d6722efb7b3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"This is the begining of hugging face where all the people you meet are going for the best you have been!\\n\\nI love seeing the expressions of how many people your heart desires, but especially when you're already happy you need to embrace your\"},\n",
              " {'generated_text': 'This is the begining of hugging face where no one can catch it.\\n\\nShifting gears and looking to meet him, I begin to pull up his jacket, only to find, in front of me, a rather thin young man with curly'}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPLEMENTATION OF DISTILGPT2 MODEL\n",
        "generator = pipeline(\"text-generation\", model = \"distilgpt2\")\n",
        "generator(\n",
        "    \"The course is suitable for a programmer so that\",\n",
        "    max_length = 20,\n",
        "    num_return_sequences = 2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hyphPTqhnYk",
        "outputId": "84560916-99b0-4299-ca36-961981b9f544"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'The course is suitable for a programmer so that it can be used to build on the next generation of'},\n",
              " {'generated_text': 'The course is suitable for a programmer so that it is not more complicated. But you can use this'}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Mask Filling` : To fill in the blanks in a given text "
      ],
      "metadata": {
        "id": "elkpwop6jQ4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unmasker = pipeline(\"fill-mask\")\n",
        "unmasker(\"The course teaches about <mask> models\", top_k = 2)     #The top_k argument controls how many possibilities you want to be displayed."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIr7DVA6immn",
        "outputId": "470e44b8-a8b2-4349-b805-770c9ddbb63e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilroberta-base (https://huggingface.co/distilroberta-base)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.2331242859363556,\n",
              "  'sequence': 'The course teaches about mathematical models',\n",
              "  'token': 30412,\n",
              "  'token_str': ' mathematical'},\n",
              " {'score': 0.0674612820148468,\n",
              "  'sequence': 'The course teaches about predictive models',\n",
              "  'token': 27930,\n",
              "  'token_str': ' predictive'}]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Name Entity Recognition`\n",
        "\n",
        "**NER** is a task where the model has to find which parts of the input text correspond to entities such as persons, locations, or organizations"
      ],
      "metadata": {
        "id": "81A2e8hdk9Ay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NER = pipeline(\"ner\", grouped_entities = True)\n",
        "NER(\"My name is Rebanta Aryal and I am from Kathmandu, Nepal\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58YBTHAQjcSN",
        "outputId": "b3c364f9-5299-4ef6-8e29-3f3de388de2b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/pipelines/token_classification.py:136: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
            "  \"`grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'end': 24,\n",
              "  'entity_group': 'PER',\n",
              "  'score': 0.9985151,\n",
              "  'start': 11,\n",
              "  'word': 'Rebanta Aryal'},\n",
              " {'end': 48,\n",
              "  'entity_group': 'LOC',\n",
              "  'score': 0.99885875,\n",
              "  'start': 39,\n",
              "  'word': 'Kathmandu'},\n",
              " {'end': 55,\n",
              "  'entity_group': 'LOC',\n",
              "  'score': 0.9995988,\n",
              "  'start': 50,\n",
              "  'word': 'Nepal'}]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Question Answering`\n",
        "\n",
        "The question-answering pipeline answers questions using information from a given context.\n",
        "\n",
        "This pipeline works by extracting information from the provided context; it does not generate the answer."
      ],
      "metadata": {
        "id": "sggkFEeemZYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question_answer = pipeline(\"question-answering\")\n",
        "question_answer(\n",
        "    question = \"where do i live ?\", \n",
        "    context = \"My name is Rebanta and I am from Kathmandu, Nepal\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS08rXUilffJ",
        "outputId": "aacefc78-3d91-40ce-d31c-7defb973270f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'Kathmandu, Nepal',\n",
              " 'end': 49,\n",
              " 'score': 0.6519007682800293,\n",
              " 'start': 33}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Summarization` \n",
        "Summarization is the task of reducing a text into a shorter text while keeping all (or most) of the important aspects referenced in the text.\n"
      ],
      "metadata": {
        "id": "15PXdim0naAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarize = pipeline(\"summarization\")\n",
        "summarize(\"\"\"\n",
        "    America has changed dramatically during recent years. Not only has the number of \n",
        "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
        "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
        "    the premier American universities engineering curricula now concentrate on \n",
        "    and encourage largely the study of engineering science. As a result, there \n",
        "    are declining offerings in engineering subjects dealing with infrastructure, \n",
        "    the environment, and related issues, and greater concentration on high \n",
        "    technology subjects, largely supporting increasingly complex scientific \n",
        "    developments. While the latter is important, it should not be at the expense \n",
        "    of more traditional engineering.\n",
        "\n",
        "    Rapidly developing economies such as China and India, as well as other \n",
        "    industrial countries in Europe and Asia, continue to encourage and advance \n",
        "    the teaching of engineering. Both China and India, respectively, graduate \n",
        "    six and eight times as many traditional engineers as does the United States. \n",
        "    Other industrial countries at minimum maintain their output, while America \n",
        "    suffers an increasingly serious decline in the number of engineering graduates \n",
        "    and a lack of well-educated engineers.\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Q04g2f-mqXz",
        "outputId": "08dc2ce5-59d0-4f65-cd72-62cc1dfcb055"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 (https://huggingface.co/sshleifer/distilbart-cnn-12-6)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': ' America has changed dramatically during recent years . The number of engineering graduates in the U.S. has declined in traditional engineering disciplines such as mechanical, civil,    electrical, chemical, and aeronautical engineering . Rapidly developing economies such as China and India continue to encourage and advance the teaching of engineering .'}]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ]
}